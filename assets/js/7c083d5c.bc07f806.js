"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9420],{3250:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>o,default:()=>a,frontMatter:()=>d,metadata:()=>c,toc:()=>l});var i=t(4848),s=t(8453);const d={sidebar_position:3},o="\ud83e\udde0 Agents and Capabilities",c={id:"usage/agents",title:"\ud83e\udde0 Agents and Capabilities",description:"Monologue Agent",source:"@site/docs/usage/agents.md",sourceDirName:"usage",slug:"/usage/agents",permalink:"/OpenDevin/docs/usage/agents",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"docsSidebar",previous:{title:"Local LLM with Ollama",permalink:"/OpenDevin/docs/usage/llms/localLLMs"},next:{title:"\ud83d\udea7 Troubleshooting",permalink:"/OpenDevin/docs/usage/troubleshooting/"}},r={},l=[{value:"Monologue Agent",id:"monologue-agent",level:2},{value:"Description",id:"description",level:3},{value:"Actions",id:"actions",level:3},{value:"Observations",id:"observations",level:3},{value:"Methods",id:"methods",level:3},{value:"Planner Agent",id:"planner-agent",level:2},{value:"Description",id:"description-1",level:3},{value:"Actions",id:"actions-1",level:3},{value:"Observations",id:"observations-1",level:3},{value:"Methods",id:"methods-1",level:3},{value:"CodeAct Agent",id:"codeact-agent",level:2},{value:"Description",id:"description-2",level:3},{value:"Actions",id:"actions-2",level:3},{value:"Observations",id:"observations-2",level:3},{value:"Methods",id:"methods-2",level:3}];function h(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",p:"p",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"-agents-and-capabilities",children:"\ud83e\udde0 Agents and Capabilities"}),"\n",(0,i.jsx)(n.h2,{id:"monologue-agent",children:"Monologue Agent"}),"\n",(0,i.jsx)(n.h3,{id:"description",children:"Description"}),"\n",(0,i.jsx)(n.p,{children:"The Monologue Agent utilizes long and short term memory to complete tasks.\nLong term memory is stored as a LongTermMemory object and the model uses it to search for examples from the past.\nShort term memory is stored as a Monologue object and the model can condense it as necessary."}),"\n",(0,i.jsx)(n.h3,{id:"actions",children:"Actions"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"Action"}),",\n",(0,i.jsx)(n.code,{children:"NullAction"}),",\n",(0,i.jsx)(n.code,{children:"CmdRunAction"}),",\n",(0,i.jsx)(n.code,{children:"FileWriteAction"}),",\n",(0,i.jsx)(n.code,{children:"FileReadAction"}),",\n",(0,i.jsx)(n.code,{children:"AgentRecallAction"}),",\n",(0,i.jsx)(n.code,{children:"BrowseURLAction"}),",\n",(0,i.jsx)(n.code,{children:"AgentThinkAction"})]}),"\n",(0,i.jsx)(n.h3,{id:"observations",children:"Observations"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"Observation"}),",\n",(0,i.jsx)(n.code,{children:"NullObservation"}),",\n",(0,i.jsx)(n.code,{children:"CmdOutputObservation"}),",\n",(0,i.jsx)(n.code,{children:"FileReadObservation"}),",\n",(0,i.jsx)(n.code,{children:"AgentRecallObservation"}),",\n",(0,i.jsx)(n.code,{children:"BrowserOutputObservation"})]}),"\n",(0,i.jsx)(n.h3,{id:"methods",children:"Methods"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Method"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"__init__"})}),(0,i.jsx)(n.td,{children:"Initializes the agent with a long term memory, and an internal monologue"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_add_event"})}),(0,i.jsx)(n.td,{children:"Appends events to the monologue of the agent and condenses with summary automatically if the monologue is too long"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_initialize"})}),(0,i.jsxs)(n.td,{children:["Utilizes the ",(0,i.jsx)(n.code,{children:"INITIAL_THOUGHTS"})," list to give the agent a context for its capabilities and how to navigate the ",(0,i.jsx)(n.code,{children:"/workspace"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"step"})}),(0,i.jsx)(n.td,{children:"Modifies the current state by adding the most recent actions and observations, then prompts the model to think about its next action to take."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"search_memory"})}),(0,i.jsxs)(n.td,{children:["Uses ",(0,i.jsx)(n.code,{children:"VectorIndexRetriever"})," to find related memories within the long term memory."]})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"planner-agent",children:"Planner Agent"}),"\n",(0,i.jsx)(n.h3,{id:"description-1",children:"Description"}),"\n",(0,i.jsx)(n.p,{children:"The planner agent utilizes a special prompting strategy to create long term plans for solving problems.\nThe agent is given its previous action-observation pairs, current task, and hint based on last action taken at every step."}),"\n",(0,i.jsx)(n.h3,{id:"actions-1",children:"Actions"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"NullAction"}),",\n",(0,i.jsx)(n.code,{children:"CmdRunAction"}),",\n",(0,i.jsx)(n.code,{children:"CmdKillAction"}),",\n",(0,i.jsx)(n.code,{children:"BrowseURLAction"}),",\n",(0,i.jsx)(n.code,{children:"FileReadAction"}),",\n",(0,i.jsx)(n.code,{children:"FileWriteAction"}),",\n",(0,i.jsx)(n.code,{children:"AgentRecallAction"}),",\n",(0,i.jsx)(n.code,{children:"AgentThinkAction"}),",\n",(0,i.jsx)(n.code,{children:"AgentFinishAction"}),",\n",(0,i.jsx)(n.code,{children:"AgentSummarizeAction"}),",\n",(0,i.jsx)(n.code,{children:"AddTaskAction"}),",\n",(0,i.jsx)(n.code,{children:"ModifyTaskAction"}),","]}),"\n",(0,i.jsx)(n.h3,{id:"observations-1",children:"Observations"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"Observation"}),",\n",(0,i.jsx)(n.code,{children:"NullObservation"}),",\n",(0,i.jsx)(n.code,{children:"CmdOutputObservation"}),",\n",(0,i.jsx)(n.code,{children:"FileReadObservation"}),",\n",(0,i.jsx)(n.code,{children:"AgentRecallObservation"}),",\n",(0,i.jsx)(n.code,{children:"BrowserOutputObservation"})]}),"\n",(0,i.jsx)(n.h3,{id:"methods-1",children:"Methods"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Method"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"__init__"})}),(0,i.jsxs)(n.td,{children:["Initializes an agent with ",(0,i.jsx)(n.code,{children:"llm"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"step"})}),(0,i.jsxs)(n.td,{children:["Checks to see if current step is completed, returns ",(0,i.jsx)(n.code,{children:"AgentFinishAction"})," if True. Otherwise, creates a plan prompt and sends to model for inference, adding the result as the next action."]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"search_memory"})}),(0,i.jsx)(n.td,{children:"Not yet implemented"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"codeact-agent",children:"CodeAct Agent"}),"\n",(0,i.jsx)(n.h3,{id:"description-2",children:"Description"}),"\n",(0,i.jsx)(n.p,{children:"The Code Act Agent is a minimalist agent. The agent works by passing the model a list of action-observation pairs and prompting the model to take the next step."}),"\n",(0,i.jsx)(n.h3,{id:"actions-2",children:"Actions"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"Action"}),",\n",(0,i.jsx)(n.code,{children:"CmdRunAction"}),",\n",(0,i.jsx)(n.code,{children:"AgentEchoAction"}),",\n",(0,i.jsx)(n.code,{children:"AgentFinishAction"}),","]}),"\n",(0,i.jsx)(n.h3,{id:"observations-2",children:"Observations"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"CmdOutputObservation"}),",\n",(0,i.jsx)(n.code,{children:"AgentMessageObservation"}),","]}),"\n",(0,i.jsx)(n.h3,{id:"methods-2",children:"Methods"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Method"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"__init__"})}),(0,i.jsxs)(n.td,{children:["Initializes an agent with ",(0,i.jsx)(n.code,{children:"llm"})," and a list of messages ",(0,i.jsx)(n.code,{children:"List[Mapping[str, str]]"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"step"})}),(0,i.jsxs)(n.td,{children:["First, gets messages from state and then compiles them into a list for context. Next, pass the context list with the prompt to get the next command to execute. Finally, Execute command if valid, else return ",(0,i.jsx)(n.code,{children:"AgentEchoAction(INVALID_INPUT_MESSAGE)"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"search_memory"})}),(0,i.jsx)(n.td,{children:"Not yet implemented"})]})]})]})]})}function a(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>c});var i=t(6540);const s={},d=i.createContext(s);function o(e){const n=i.useContext(d);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(d.Provider,{value:n},e.children)}}}]);